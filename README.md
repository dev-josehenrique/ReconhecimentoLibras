# ğŸ¤Ÿ Reconhecimento de Gestos da LÃ­ngua Brasileira de Sinais 
para InclusÃ£o Educacional

Trabalho desenvolvido como **Projeto Final da disciplina de Sistemas MultimÃ­dias**, por **JosÃ© Henrique Lopes Motta**.  
Este sistema realiza o reconhecimento de gestos do alfabeto da LÃ­ngua Brasileira de Sinais (LIBRAS) utilizando **OpenCV**, **MediaPipe** e um modelo de classificaÃ§Ã£o treinado em **TensorFlow/Keras**.  
O objetivo principal Ã© promover a **inclusÃ£o educacional de pessoas surdas**, oferecendo uma aplicaÃ§Ã£o interativa baseada em visÃ£o computacional.


---

## ğŸ“¸ DemonstraÃ§Ã£o

![DemonstraÃ§Ã£o do sistema](OIUFSC.gif)

---

## ğŸš€ Tecnologias Utilizadas

- **Python** 3.8.0
- **TensorFlow** 2.8.0
- **MediaPipe** 0.10.5
- **OpenCV-Python** 4.6.0.66
- **Protobuf** 3.19.4
- Modelo `.h5` treinado com [Teachable Machine](https://teachablemachine.withgoogle.com/)

---

## âš™ï¸ Requisitos

Certifique-se de estar utilizando **Python 3.8.0** ou compatÃ­vel com TensorFlow 2.8.0.  
Use um ambiente virtual para isolar as dependÃªncias.

### InstalaÃ§Ã£o das dependÃªncias:

```bash
pip install -r requirements.txt
```

### ConteÃºdo do `requirements.txt`

```txt
tensorflow==2.8.0
mediapipe==0.10.5
opencv-python==4.6.0.66
protobuf==3.19.4
```

> âš ï¸ **AtenÃ§Ã£o:** Python 3.11 ou superior pode apresentar **incompatibilidades** com as versÃµes utilizadas do TensorFlow (2.8.0) e MediaPipe (0.10.5).  
> âœ… Recomenda-se o uso do **Python 3.8.0**, versÃ£o testada e compatÃ­vel com este projeto.


---

## â–¶ï¸ Como Rodar o Projeto

Clone o repositÃ³rio:

```bash
git clone https://github.com/dev-josehenrique/ReconhecimentoLibras.git
cd ReconhecimentoLibras
```

Crie e ative o ambiente virtual:

```bash
python -m venv venv
venv\Scripts\activate    # Windows
source venv/bin/activate  # Linux / Mac
```

Instale as dependÃªncias:

```bash
pip install -r requirements.txt
```

Execute o programa:

```bash
python main.py
```

> Pressione **'q'** para encerrar a execuÃ§Ã£o.

---

## ğŸ“‚ Estrutura do Projeto

```
ReconhecimentoLibras/
â”‚
â”œâ”€â”€ main.py              # CÃ³digo principal do sistema
â”œâ”€â”€ keras_model.h5       # Modelo de reconhecimento treinado
â”œâ”€â”€ requirements.txt     # Lista de dependÃªncias do projeto
â””â”€â”€ README.md            # DocumentaÃ§Ã£o do projeto

> ğŸ“ **ObservaÃ§Ã£o** : para exibir as imagens acima corretamente no `README.md`, 
 criei uma pasta chamada `img` dentro do projeto e coloque os arquivos lÃ¡. Essa pasta
 **nÃ£o Ã© necessÃ¡ria para a execuÃ§Ã£o do sistema**, serve apenas para fins de documentaÃ§Ã£o e exibiÃ§Ã£o no GitHub.

```

---

## ğŸ“º VÃ­deo e Imagens

Abaixo, demonstraÃ§Ãµes visuais do sistema em funcionamento:

- âœ… VÃ­deo demonstrando o **treinamento do modelo** e a realizaÃ§Ã£o de **gestos em Libras**  
  ![Treinamento do modelo](img/modelo_treinamento.gif)

- âœ… Imagem mostrando o sistema **testando o modelo treinado** e exibindo sua **precisÃ£o de prediÃ§Ã£o**  
  ![Teste do modelo](img/modelo_testando_resultado.png)

- âœ… Imagem com o **alfabeto em Libras** usado como base para o treinamento  
  ![Alfabeto em Libras](img/alfabeto_libras.png)


---

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a [MIT License](LICENSE).

---

## ğŸ‘¨â€ğŸ’» Autor

**JosÃ© Henrique Lopes Motta**  
GitHub: [@dev-josehenrique](https://github.com/dev-josehenrique)
PortfÃ³lio : [devjosehenrique.com.br](https://devjosehenrique.com.br)

---

## ğŸ™ Agradecimentos

Este projeto foi possÃ­vel graÃ§as Ã s seguintes bibliotecas, ferramentas e comunidades:

- [Google Teachable Machine](https://teachablemachine.withgoogle.com/) â€“ Treinamento do modelo de reconhecimento de gestos
- [MediaPipe Hands API](https://google.github.io/mediapipe/solutions/hands.html) â€“ DetecÃ§Ã£o de mÃ£os em tempo real
- [TensorFlow](https://www.tensorflow.org/) â€“ ExecuÃ§Ã£o do modelo de machine learning (.h5)
- [Keras](https://keras.io/) â€“ API de alto nÃ­vel usada para construir e treinar o modelo
- [OpenCV-Python](https://pypi.org/project/opencv-python/) â€“ Captura e exibiÃ§Ã£o de vÃ­deo, manipulaÃ§Ã£o de imagem
- [NumPy](https://numpy.org/) â€“ ManipulaÃ§Ã£o de arrays e normalizaÃ§Ã£o de dados
- [Protobuf (Protocol Buffers)](https://developers.google.com/protocol-buffers) â€“ ComunicaÃ§Ã£o interna entre componentes do MediaPipe
- [Python](https://www.python.org/) â€“ Linguagem base utilizada no desenvolvimento
- Comunidade Python e desenvolvedores de visÃ£o computacional, cujos tutoriais, fÃ³runs e projetos serviram de referÃªncia e apoio
